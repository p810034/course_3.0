{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b3b3f9",
   "metadata": {
    "id": "96e7967e"
   },
   "source": [
    "# Unet\n",
    "source: https://amaarora.github.io/2020/09/13/unet.html\n",
    "\n",
    "<img src=\"https://i.imgur.com/LQORH9i.png\" alt=\"drawing\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "410b7424",
   "metadata": {
    "executionInfo": {
     "elapsed": 2400,
     "status": "ok",
     "timestamp": 1677210368143,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "72ced7a4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, Sequential, layers\n",
    "# import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "104fe5ee",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677210368144,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "90f22d75"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f66ec94",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677210368144,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "a02decc3"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_LABELS = 1\n",
    "WIDTH = 512\n",
    "HEIGHT = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbef44e",
   "metadata": {
    "id": "a2bd56bc"
   },
   "source": [
    "## ConvBlock\n",
    "- 加入Instance Norm.\n",
    "- <img src=\"https://miro.medium.com/max/983/1*p84Hsn4-e60_nZPllkxGZQ.png\" width=\"50%\">\n",
    "\n",
    "> 上圖為一整個batch的feature-map。輸入6張圖片，輸入6chs, 輸出也是6chs(C方向看進去是channel, N方向看進去是圖片)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eeca9ee6",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677210368144,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "b55ade8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9:9: E731 do not assign a lambda expression, use a def\n"
     ]
    }
   ],
   "source": [
    "class convBlock(layers.Layer):\n",
    "    def __init__(self, out_ch, padding='same', kernel_size=3):\n",
    "        super().__init__()\n",
    "        kernel_size = kernel_size\n",
    "        pad_size = lambda kernel_size: (kernel_size-1)//2\n",
    "        if padding == 'same':\n",
    "            self.padding = pad_size(kernel_size)\n",
    "        else:\n",
    "            self.padding = padding\n",
    "\n",
    "        self.conv_1 = layers.Conv2D(out_ch, (3, 3),\n",
    "                                    strides=(1, 1), padding='same')\n",
    "        self.relu = layers.Activation('relu')\n",
    "\n",
    "        self.conv_2 = layers.Conv2D(out_ch, (3, 3),\n",
    "                                    strides=(1, 1), padding='same')\n",
    "\n",
    "    def call(self, input, training=None):\n",
    "        x = self.conv_1(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a2e3f13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4750,
     "status": "ok",
     "timestamp": 1677210372891,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "b581420f",
    "outputId": "db45fc76-798b-411b-d52d-c33eaad64f77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 512, 512, 64])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = convBlock(64)\n",
    "inputs = np.zeros((1, HEIGHT, WIDTH, 3), dtype=np.float32)\n",
    "block(inputs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302de6fd",
   "metadata": {
    "id": "76ff1d7b"
   },
   "source": [
    "## Encoder(DownStream)\n",
    "將影像進行編碼，過程中解析度會縮小(maxpooling、convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd627ec",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677210372892,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "80035ad9"
   },
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, chs=(32, 64, 128, 256, 512), padding='same'):\n",
    "        super().__init__()\n",
    "        self.FPN_enc_ftrs = [convBlock(chs[i]) for i in range(len(chs))]\n",
    "        self.pool = layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                        strides=(2, 2), padding=padding)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        features = []\n",
    "        for block in self.FPN_enc_ftrs:\n",
    "            x = block(x)\n",
    "            features.append(x)\n",
    "            x = self.pool(x)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca98b06b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1677210373547,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "4e9fe52b",
    "outputId": "e67aec62-80bc-4632-fa08-528ebe6f698c"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "inputs = np.zeros((1, HEIGHT, WIDTH, 3), dtype=np.float32)\n",
    "features = encoder(inputs)\n",
    "for f in features:\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dafc56c",
   "metadata": {
    "id": "f4ccc12e"
   },
   "source": [
    "## Decoder(UpStream)\n",
    "將編碼還原成影像，過程中解析度會放大直到回復成輸入影像解析度(transposed Convolution)。\n",
    "- 將編碼還原成影像是因為影像分割是pixel-wise的精度進行預測，解析度被還原後，就可以知道指定pixel位置所對應的類別\n",
    "- 類別資訊通常用feature-map的channels(chs)去劃分，一個channel代表一個class\n",
    "- 有許多UNet模型架構會有輸入576x576，但輸出只有388x388的情況，是因為他們沒有對卷積過程做padding，導致解析度自然下降。最後只要把mask resize到388x388就能繼續計算loss。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06971e10",
   "metadata": {
    "id": "0a83ecc8"
   },
   "source": [
    "### Transposed Conv and UpsampleConv\n",
    "<img src=\"https://i.imgur.com/eIIJxre.png\" alt=\"drawing\" width=\"300\"/>\n",
    "<img src=\"https://i.imgur.com/uLo7icF.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "Transposed Conv \n",
    "- 透過上面的操作做轉置卷積，feature-map上的數值會作為常數與kernel相乘\n",
    "- 會導致Gridding Effect(棋盤格效應)\n",
    "\n",
    "UpsampleConv\n",
    "- 先做上採樣(Upsample/ Unpooling)\n",
    "- 然後作卷積(padding = same)\n",
    "<!-- #### 替代方案 UpSampling(Unpooling)+Convolution -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c8bd21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677210373547,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "4fe2e662",
    "outputId": "3a52c372-328f-45b8-e7c6-de2d260efb28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 56, 56, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvTranspose2d透過設定k=2, s=2, output_padding=0可以讓影像從28x28變成56x56\n",
    "\n",
    "x = np.zeros((1, 28, 28, 3), dtype=np.float32)\n",
    "x = layers.Conv2DTranspose(30, kernel_size=(2, 2),\n",
    "                           strides=(2, 2), padding='valid')(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51aad22b",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677210373547,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "52e737d2"
   },
   "outputs": [],
   "source": [
    "class UpSampleConvs(layers.Layer):\n",
    "    def __init__(self, out_ch, padding='same'):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv2D(out_ch, (3, 3),\n",
    "                                  strides=(1, 1), padding=padding)\n",
    "        self.relu = layers.Activation('relu')\n",
    "        self.upSample = layers.UpSampling2D(size=2)\n",
    "#         self.INorm = tfa.layers.InstanceNormalization(axis=3,\n",
    "#                                                       center=True,\n",
    "#                                                       scale=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.upSample(x)\n",
    "        x = self.conv(x)\n",
    "        # x = self.INorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2171274b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677210373547,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "341eefa1",
    "outputId": "0d903f57-1a37-44dc-c0ff-e894a5a5b428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 56, 56, 30)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((1, 28, 28, 3), dtype=np.float32)\n",
    "x = UpSampleConvs(30)(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4eb607",
   "metadata": {
    "id": "a2bd00bd"
   },
   "source": [
    "### decoder(上採樣) module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5738496",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677210373548,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "3dbca47e"
   },
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, chs=(256, 128, 64, 32), padding='same'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.chs = chs\n",
    "        self.padding = padding\n",
    "        # 上採樣後卷積\n",
    "        self.upconvs = [UpSampleConvs(chs[i], padding=padding)\n",
    "                        for i in range(len(chs))]\n",
    "        self.FPN_dec_ftrs = [convBlock(chs[i], padding=padding)\n",
    "                             for i in range(len(chs))]\n",
    "\n",
    "    def call(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)):\n",
    "            enc_ftrs = encoder_features[i]\n",
    "            x = self.upconvs[i](x)\n",
    "\n",
    "            # enc_ftrs = self.crop(encoder_features[i], x)\n",
    "            x = layers.Concatenate(axis=-1)([x, enc_ftrs])\n",
    "            x = self.FPN_dec_ftrs[i](x)\n",
    "        return x\n",
    "\n",
    "    def crop(self, enc_ftrs, x):\n",
    "        _, H, W, _ = x.shape\n",
    "        enc_ftrs = layers.CenterCrop(H, W)(enc_ftrs)\n",
    "        return enc_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e70088c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677210373548,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "a56dde48",
    "outputId": "3dc6ac83-23a8-41e4-ceb3-f8071d9eb4ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 32)\n",
      "(1, 256, 256, 64)\n",
      "(1, 128, 128, 128)\n",
      "(1, 64, 64, 256)\n",
      "(1, 32, 32, 512)\n"
     ]
    }
   ],
   "source": [
    "for i in features:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a22b647a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1677210374552,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "681ac649",
    "outputId": "192b518b-80ea-4477-9d02-1d4879adbb6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 32)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder()\n",
    "decoder\n",
    "x = np.zeros((1, HEIGHT//16, WIDTH//16, 512), dtype=np.float32)\n",
    "print(decoder(x, features[::-1][1:]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e5bf7a",
   "metadata": {
    "id": "13a691ac"
   },
   "source": [
    "## Unet構建\n",
    "結合encoder和decoder組成Unet。\n",
    "- 在輸出層如果用softmax做多元分類問題預測的話，類別數量要+1(num_classes+background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04c5c5c3",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1677210374552,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "e23ff03a"
   },
   "outputs": [],
   "source": [
    "class UNet(Model):\n",
    "    def __init__(self, enc_chs=(64, 128, 256, 512, 1024),\n",
    "                 dec_chs=(512, 256, 128, 64),\n",
    "                 num_class=1, padding='same',\n",
    "                 retain_dim=None, activation=None):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(enc_chs, padding=padding)\n",
    "        self.decoder = Decoder(dec_chs, padding=padding)\n",
    "        self.head = layers.Conv2D(num_class, (1, 1),\n",
    "                                  strides=(1, 1), padding=padding)\n",
    "        self.retain_dim = retain_dim\n",
    "        self.activation = activation\n",
    "\n",
    "    def call(self, inputs):\n",
    "        enc_ftrs = self.encoder(inputs)\n",
    "        # 把不同尺度的所有featuremap都輸入decoder，我們在decoder需要做featuremap的拼接\n",
    "        outputs = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        outputs = self.head(outputs)\n",
    "\n",
    "        if self.retain_dim:\n",
    "            outputs = tf.image.resize(outputs,\n",
    "                                      self.retain_dim,\n",
    "                                      method='nearest')\n",
    "\n",
    "        if self.activation:\n",
    "            outputs = self.activation(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421fb213",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4004,
     "status": "ok",
     "timestamp": 1677210378555,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "925dafe1",
    "outputId": "0141dc28-e7c1-4454-82ab-0802bfac1793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 2)\n"
     ]
    }
   ],
   "source": [
    "unet = UNet(num_class=2, padding='same', retain_dim=(WIDTH, HEIGHT))\n",
    "x = np.zeros((1, WIDTH, HEIGHT, 3), dtype=np.float32)\n",
    "y_pred = unet(x)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b33dab55",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1677210378555,
     "user": {
      "displayName": "吳承澔",
      "userId": "17428420001093174904"
     },
     "user_tz": -480
    },
    "id": "bab7808f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
